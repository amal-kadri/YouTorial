{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amalkadri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x132151810>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import ssl\n",
    "import spacy\n",
    "import nltk.corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import string\n",
    "#from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "conn_string = \"postgresql://youtube-project:Zhanghaokun_6@35.226.197.36/youtube-content\"\n",
    "engine = sqlalchemy.create_engine(conn_string)\n",
    "\n",
    "sql_data = pd.read_sql_table('youtube_metrics',engine)\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"spacytextblob\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'videoID': 'pb4xXXEA8zk',\n",
       " 'views_count': 343474,\n",
       " 'likes': 9723,\n",
       " 'comments_': 365,\n",
       " 'length_': 'PT13M22S',\n",
       " 'like_ratios': 0.028307819514723095,\n",
       " 'comment_ratio': 0.0010626714103542045}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_data\n",
    "metrics = sql_data.iloc[0].to_dict()\n",
    "analysis = {\n",
    "    'videoID' : metrics['videoID'],\n",
    "    'views_count' : int(metrics['views']),\n",
    "    'likes': int(metrics['likes']),\n",
    "    'comments_' : int(metrics['comments']),\n",
    "    'length_' : metrics['length'],\n",
    "    'like_ratios' : int(metrics['likes'])/int(metrics['views']),\n",
    "    'comment_ratio' : int(metrics['comments'])/int(metrics['views'])\n",
    "}\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_sql_table('youtube_comments',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>videoID</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Hi Thoufiq, this is very impressive! I‚Äôm watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Hi Thoufiq, Thanks for sharing this informativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Hi Thoufiq, excellent video absolutely loved i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Thanks, Brother. This was a bit intricate for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>One of the best Analysis video I have seen so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125038</th>\n",
       "      <td>12</td>\n",
       "      <td>rB0TqCUD2-M</td>\n",
       "      <td>Keep the f750 content going bud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125039</th>\n",
       "      <td>13</td>\n",
       "      <td>rB0TqCUD2-M</td>\n",
       "      <td>How far is the quarry from your jobs on average?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125040</th>\n",
       "      <td>14</td>\n",
       "      <td>rB0TqCUD2-M</td>\n",
       "      <td>Not bad, Not bad at all üëçüëçüëçüëç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125041</th>\n",
       "      <td>15</td>\n",
       "      <td>rB0TqCUD2-M</td>\n",
       "      <td>Nice tractor üëç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125042</th>\n",
       "      <td>16</td>\n",
       "      <td>rB0TqCUD2-M</td>\n",
       "      <td>*Nice tractor how many HP?*  #WorldsOkayestFarmer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125043 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index      videoID                                            comment\n",
       "0           0  SwSbnmqk3zY  Hi Thoufiq, this is very impressive! I‚Äôm watch...\n",
       "1           1  SwSbnmqk3zY  Hi Thoufiq, Thanks for sharing this informativ...\n",
       "2           2  SwSbnmqk3zY  Hi Thoufiq, excellent video absolutely loved i...\n",
       "3           3  SwSbnmqk3zY  Thanks, Brother. This was a bit intricate for ...\n",
       "4           4  SwSbnmqk3zY  One of the best Analysis video I have seen so ...\n",
       "...       ...          ...                                                ...\n",
       "125038     12  rB0TqCUD2-M                    Keep the f750 content going bud\n",
       "125039     13  rB0TqCUD2-M   How far is the quarry from your jobs on average?\n",
       "125040     14  rB0TqCUD2-M                       Not bad, Not bad at all üëçüëçüëçüëç\n",
       "125041     15  rB0TqCUD2-M                                     Nice tractor üëç\n",
       "125042     16  rB0TqCUD2-M  *Nice tractor how many HP?*  #WorldsOkayestFarmer\n",
       "\n",
       "[125043 rows x 3 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‚Äò‚Äô‚Äú‚Äù‚Ä¶]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('[‚Äò‚Äô‚Äú‚Äù‚Ä¶]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('/(\\s\\s\\s*)/g', ' ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_analysis = comments_df[['videoID','comment']].drop_duplicates().head(100)\n",
    "comm_analysis['comment'] = comm_analysis.groupby(['videoID'])['comment'].transform(lambda x : ' '.join(x))\n",
    "comm_analysis = comm_analysis.drop_duplicates().reset_index()[['videoID','comment']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Thoufiq, this is very impressive! I‚Äôm watching this purely out of curiosity bc I‚Äôve not started my python class yet; however, I would love to see SQL project ideas, maybe for data cleaning and/or analysis.   Thanks as always for your clear explanations and guidance üëçüèª Also very glad to see you‚Äôre closing in on 15K, friend!!   Congratulations in advance üòÄüëåüèªüôèüèª Hi Thoufiq, Thanks for sharing this informative & interesting video. I was wondering can we extract the actual comments with replies instead of comment count in this example. Thanks in advance. Hi Thoufiq, excellent video absolutely loved it please keep creating many more project videos. Can you make a short video on how to visualize data using python as Dynamic Radar Charts (i.e Player vs player comparision/company vs company - you can filter which two competitors to compare) Thanks, Brother. This was a bit intricate for me as I have just started out learning Python for Data Analysis but the tricks you have used are new and I am eager to learn and use them and create a new project based off of this information.  Don\\'t worry, keep at it, you will be bigger than Ken Jee one day, just stay consistent. One of the best Analysis video I have seen so far\\nAmazing Content , Expecting videos on some more projects  .\\nAppreciate your hard work !! Hi, great tutorial! Congratulations for your work! It really helped me a lot to know how to work with Youtube API. Hi Thoufiq, this is very useful video, your content is really helpful for people like us who are freshers and want to pursue career in data analytics. Actually, I am trying the same project but i am stucked at the jupyter notebook. It doesn\\'t show the virtual environment kernal that i have created for this project. I tried to solve this problem by installing ipy kernal and displaying kernal name but still, notebook doesn\\'t show the virtual environment kernal that i have created. Can you please help me with this? Hi Thoufiq, great tutorial! Just getting started here with Python. One quick question. I don\\'t see the YT-env in my jupyter notebook, but did start jupyter from the YT-env in my terminal. Any idea on where this went wrong? Kind regards! Stephan Great tutorial, thanks Bro. Also would highly appreciate If you can make similar video on \"how to grab each viewers Data\". I have been looking for extracting periodical data (Day, Week, Month etc) of viewership, subscribers, comments, likes & Dislikes etc of each user, so as to export it to the Google Sheet for rendering the process. Further any other references or sources to this subject referred shall be highly appreciated Was waiting for thisüòÉThanks a lot brother for this very helpful videoüëåüèª \\nWay to goüôåüèª Thanks a lot for this  video!!! üòäüòä\\nBtw liked and ofc already subscribed.\\n\\nPlease upload more videos of projects Hi Thoufiq, great job you\\'re doing. Absolutely love this. I\\'d like to know if you\\'ve worked on getting all the channel ids of youtubers based on their location or country. i.e. All channel ids in a country. Also, while working on this project I got errors (\\'reason\\': \\'playlistNotFound\\') trying to access the video ids using the playlist ids and I have been unable to go passed that. Any idea on what the issue might be? Thanks for your educative content. Kind regards. Hey taufiq, how to prepare/ask these questions while practicing SQL with datasets? Elaborate in detail in upcoming videos. Thank you Brother, Great tutorial, good explanation. it worked for me. can you please make a video on how to extract all the comments, likes and dislikes for each comment, user name, comment date. it will help me a lot. thank you for your great explanation. Fab as always... concise and on fleek. Keep upüëåüèªüëåüèªüôè Excellent work and great explanation sir.. waiting for more of challenging videos Really interested in this stuff and fabulous explanation ...Also please do videos on Data science how to begin from scratch ......üôåüôå I used to be a C and SQL programmer but now I am retired.\\nI want to download all my comments I have made over the years on different YouTube into a table or database I can store locally.\\nYou seem to have done exactly what I need to do.\\nCan I access all the necessary codes that I can just copy and paste?\\nI will be most grateful. Thank you, very awesome tutorial üî•üòé Amazing video.. thank you so much.\\nI would like to know how to get video details of multiple channels at a time. Can you please suggest how to do it. Thanks for this informative video,  how to get all comments ( personal youtube channel)  with permission using API? And  Can the above data be stored in the text file in real-time? Great class! Bro - Thank you very much for this, I got an issue though I run my project in Visual studio I added 7 links to analyze 7 channels instead of 4 and it only shows me 4. and then It shows me all these errors..  ---------------------------------------------------------------------------\\r\\nIndexError                                Traceback (most recent call last)\\r\\nc:\\\\Users\\\\UTENTE\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\YT-Analysis-project.ipynb Cell 14\\' in <module>\\r\\n----> 1 playlist_id = channel_data.loc[channel_data[\\'Channel_name\\']==\\'Ken Jee\\', \\'playlist_id\\'].iloc[0]\\r\\n\\r\\nFile ~\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexing.py:967, in _LocationIndexer.__getitem__(self, key)\\r\\n    964 axis = self.axis or 0\\r\\n    966 maybe_callable = com.apply_if_callable(key, self.obj)\\r\\n--> 967 return self._getitem_axis(maybe_callable, axis=axis)\\r\\n\\r\\nFile ~\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexing.py:1520, in _iLocIndexer._getitem_axis(self, key, axis)\\r\\n   1517     raise TypeError(\"Cannot index by location index with a non-integer key\")\\r\\n   1519 # validate the location\\r\\n-> 1520 self._validate_integer(key, axis)\\r\\n   1522 return self.obj._ixs(key, axis=axis)\\r\\n\\r\\nFile ~\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexing.py:1452, in _iLocIndexer._validate_integer(self, key, axis)\\r\\n   1450 len_axis = len(self.obj._get_axis(axis))\\r\\n   1451 if key >= len_axis or key < -len_axis:\\r\\n-> 1452     raise IndexError(\"single positional indexer is out-of-bounds\")\\r\\n\\r\\nIndexError: single positional indexer is out-of-bounds\\n\\n\\n**Can you help me please** Thanks for valuable information You are so brilliant ü•≥ü•≥ü•≥üôèüôèüíê'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########testing\n",
    "comments_from_id = comments_df[comments_df['videoID'] == 'SwSbnmqk3zY']\n",
    "comment_list = comments_from_id['comment'].to_list()\n",
    "dirty_text = ' '.join(comment_list)\n",
    "dirty_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_analysis['clean'] =  comm_analysis['comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "comm_analysis['clean'] = comm_analysis['clean'].transform(lambda txt: clean_text_round1(txt)).transform(lambda txt: clean_text_round2(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30122663921444404"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = comm_analysis['clean'][0]\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"spacytextblob\")\n",
    "nlp(text)._.blob.polarity\n",
    "\n",
    "# print(doc._.blob.polarity)\n",
    "# print(doc._.blob.subjectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(txt):\n",
    "    return nlp(txt)._.blob.polarity\n",
    "polarity_getter = get_polarity\n",
    "def get_subjectivity(txt):\n",
    "    return nlp(txt)._.blob.subjectivity\n",
    "subjectivity_getter = get_subjectivity\n",
    "\n",
    "def get_sentiment(txt):\n",
    "    doc = nlp(txt)\n",
    "    sentiment_list = [doc._.blob.polarity,doc._.blob.subjectivity]\n",
    "    return sentiment_list\n",
    "sentiment_getter = get_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoID</th>\n",
       "      <th>comment</th>\n",
       "      <th>clean</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>Hi Thoufiq, this is very impressive! I‚Äôm watch...</td>\n",
       "      <td>hi thoufiq impressive im watching purely curio...</td>\n",
       "      <td>0.301227</td>\n",
       "      <td>0.545183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_xNI6tuOeI</td>\n",
       "      <td>Very Impressive finishing work. Nice to see th...</td>\n",
       "      <td>very impressive finishing work nice see pride ...</td>\n",
       "      <td>0.352873</td>\n",
       "      <td>0.541713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vGJL0BgVMOw</td>\n",
       "      <td>perfect taste combination... gonna try this re...</td>\n",
       "      <td>perfect taste combination gonna try recipe üòãüòãn...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ianApRDflh0</td>\n",
       "      <td>Here‚Äôs the potato harvest! https://youtu.be/UK...</td>\n",
       "      <td>heres potato harvest httpsyoutubeukmsnboeofe i...</td>\n",
       "      <td>0.271048</td>\n",
       "      <td>0.480078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8nQUQJKnX0E</td>\n",
       "      <td>Good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K4a3dTScBlg</td>\n",
       "      <td>Having a toilet was must for our camper van an...</td>\n",
       "      <td>having toilet must camper van were super happy...</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.486941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pb4xXXEA8zk</td>\n",
       "      <td>Girl!! You are on a serious streak with these ...</td>\n",
       "      <td>girl you serious streak last few i mean i love...</td>\n",
       "      <td>0.120417</td>\n",
       "      <td>0.537083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoID                                            comment  \\\n",
       "0  SwSbnmqk3zY  Hi Thoufiq, this is very impressive! I‚Äôm watch...   \n",
       "1  B_xNI6tuOeI  Very Impressive finishing work. Nice to see th...   \n",
       "2  vGJL0BgVMOw  perfect taste combination... gonna try this re...   \n",
       "3  ianApRDflh0  Here‚Äôs the potato harvest! https://youtu.be/UK...   \n",
       "4  8nQUQJKnX0E                                               Good   \n",
       "5  K4a3dTScBlg  Having a toilet was must for our camper van an...   \n",
       "6  pb4xXXEA8zk  Girl!! You are on a serious streak with these ...   \n",
       "\n",
       "                                               clean  polarity  subjectivity  \n",
       "0  hi thoufiq impressive im watching purely curio...  0.301227      0.545183  \n",
       "1  very impressive finishing work nice see pride ...  0.352873      0.541713  \n",
       "2  perfect taste combination gonna try recipe üòãüòãn...  0.600000      0.920000  \n",
       "3  heres potato harvest httpsyoutubeukmsnboeofe i...  0.271048      0.480078  \n",
       "4                                               good  0.700000      0.600000  \n",
       "5  having toilet must camper van were super happy...  0.237805      0.486941  \n",
       "6  girl you serious streak last few i mean i love...  0.120417      0.537083  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text_analysis = comm_analysis\n",
    "final_text_analysis['polarity'] = final_text_analysis['clean'].apply(polarity_getter)\n",
    "final_text_analysis['subjectivity'] = final_text_analysis['clean'].apply(subjectivity_getter)\n",
    "final_text_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/18/lvwyjtw159jgvq01xkgtwzj00000gn/T/ipykernel_25120/2195161609.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_text_analysis[['polarity','subjectivity']] = pd.DataFrame(final_text_analysis['clean'].apply(sentiment_getter).to_list(), columns =   ['polarity','subjectivity'])\n",
      "/var/folders/18/lvwyjtw159jgvq01xkgtwzj00000gn/T/ipykernel_25120/2195161609.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_text_analysis[['polarity','subjectivity']] = pd.DataFrame(final_text_analysis['clean'].apply(sentiment_getter).to_list(), columns =   ['polarity','subjectivity'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoID</th>\n",
       "      <th>clean</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SwSbnmqk3zY</td>\n",
       "      <td>hi thoufiq impressive im watching purely curio...</td>\n",
       "      <td>0.301227</td>\n",
       "      <td>0.545183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_xNI6tuOeI</td>\n",
       "      <td>very impressive finishing work nice see pride ...</td>\n",
       "      <td>0.352873</td>\n",
       "      <td>0.541713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vGJL0BgVMOw</td>\n",
       "      <td>perfect taste combination gonna try recipe üòãüòãn...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ianApRDflh0</td>\n",
       "      <td>heres potato harvest httpsyoutubeukmsnboeofe i...</td>\n",
       "      <td>0.271048</td>\n",
       "      <td>0.480078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8nQUQJKnX0E</td>\n",
       "      <td>good</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K4a3dTScBlg</td>\n",
       "      <td>having toilet must camper van were super happy...</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.486941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pb4xXXEA8zk</td>\n",
       "      <td>girl you serious streak last few i mean i love...</td>\n",
       "      <td>0.120417</td>\n",
       "      <td>0.537083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoID                                              clean  polarity  \\\n",
       "0  SwSbnmqk3zY  hi thoufiq impressive im watching purely curio...  0.301227   \n",
       "1  B_xNI6tuOeI  very impressive finishing work nice see pride ...  0.352873   \n",
       "2  vGJL0BgVMOw  perfect taste combination gonna try recipe üòãüòãn...  0.600000   \n",
       "3  ianApRDflh0  heres potato harvest httpsyoutubeukmsnboeofe i...  0.271048   \n",
       "4  8nQUQJKnX0E                                               good  0.700000   \n",
       "5  K4a3dTScBlg  having toilet must camper van were super happy...  0.237805   \n",
       "6  pb4xXXEA8zk  girl you serious streak last few i mean i love...  0.120417   \n",
       "\n",
       "   subjectivity  \n",
       "0      0.545183  \n",
       "1      0.541713  \n",
       "2      0.920000  \n",
       "3      0.480078  \n",
       "4      0.600000  \n",
       "5      0.486941  \n",
       "6      0.537083  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text_analysis = comm_analysis[['videoID','clean']]\n",
    "final_text_analysis[['polarity','subjectivity']] = pd.DataFrame(final_text_analysis['clean'].apply(sentiment_getter).to_list(), columns =   ['polarity','subjectivity'])\n",
    "final_text_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'videoID': 'SwSbnmqk3zY',\n",
       " 'clean': 'hi thoufiq impressive im watching purely curiosity bc ive started python class yet however i would love see sql project ideas maybe data cleaning andor analysis thanks always clear explanations guidance üëçüèª also glad see youre closing  friend congratulations advance üòÄüëåüèªüôèüèª hi thoufiq thanks sharing informative  interesting video i wondering extract actual comments replies instead comment count example thanks advance hi thoufiq excellent video absolutely loved please keep creating many project videos can make short video visualize data using python dynamic radar charts ie player vs player comparisioncompany vs company  filter two competitors compare thanks brother this bit intricate i started learning python data analysis tricks used new i eager learn use create new project based information dont worry keep it bigger ken jee one day stay consistent one best analysis video i seen far amazing content  expecting videos projects  appreciate hard work  hi great tutorial congratulations work it really helped lot know work youtube api hi thoufiq useful video content really helpful people like us freshers want pursue career data analytics actually i trying project stucked jupyter notebook it show virtual environment kernal created project i tried solve problem installing ipy kernal displaying kernal name still notebook show virtual environment kernal created can please help this hi thoufiq great tutorial just getting started python one quick question i see ytenv jupyter notebook start jupyter ytenv terminal any idea went wrong kind regards stephan great tutorial thanks bro also would highly appreciate if make similar video how grab viewers data i looking extracting periodical data day week month etc viewership subscribers comments likes  dislikes etc user export google sheet rendering process further references sources subject referred shall highly appreciated was waiting thisüòÉthanks lot brother helpful videoüëåüèª way goüôåüèª thanks lot video üòäüòä btw liked ofc already subscribed please upload videos projects hi thoufiq great job doing absolutely love this id like know worked getting channel ids youtubers based location country ie all channel ids country also working project i got errors reason playlistnotfound trying access video ids using playlist ids i unable go passed that any idea issue might be thanks educative content kind regards hey taufiq prepareask questions practicing sql datasets elaborate detail upcoming videos thank brother great tutorial good explanation worked me please make video extract comments likes dislikes comment user name comment date help lot thank great explanation fab always concise fleek keep upüëåüèªüëåüèªüôè excellent work great explanation sir waiting challenging videos really interested stuff fabulous explanation also please videos data science begin scratch üôåüôå i used c sql programmer i retired i want download comments i made years different youtube table database i store locally you seem done exactly i need do can i access necessary codes i copy paste i grateful thank you awesome tutorial üî•üòé amazing video thank much i would like know get video details multiple channels time can please suggest it thanks informative video get comments  personal youtube channel permission using api and can data stored text file realtime great class bro  thank much this i got issue though i run project visual studio i added  links analyze  channels instead  shows  it shows errors  indexerror traceback most recent call last cusersutenteappdatalocalprogramspythonytanalysisprojectipynb cell  module   playlistid  channeldatalocken jee playlistidiloc file  locationindexergetitemself key  axis  selfaxis   maybecallable  comapplyifcallablekey selfobj   return selfgetitemaxismaybecallable axisaxis file  ilocindexergetitemaxisself key axis  raise typeerrorcannot index location index noninteger key   validate location   selfvalidateintegerkey axis  return selfobjixskey axisaxis file  ilocindexervalidateintegerself key axis  lenaxis  lenselfobjgetaxisaxis  key  lenaxis key  lenaxis   raise indexerrorsingle positional indexer outofbounds indexerror single positional indexer outofbounds can help please thanks valuable information you brilliant ü•≥ü•≥ü•≥üôèüôèüíê',\n",
       " 'polarity': 0.30122663921444404,\n",
       " 'subjectivity': 0.5451834547566256}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_dict = final_text_analysis.iloc[0].to_dict()\n",
    "row_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30313164108618657, 0.5348300373868556]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = text.lower()\n",
    "# text = re.sub('\\[.*?\\]', '', text)\n",
    "# text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "# text = re.sub('\\w*\\d\\w*', '', text)\n",
    "# text = re.sub('[‚Äò‚Äô‚Äú‚Äù‚Ä¶]', '', text)\n",
    "# text = re.sub('\\n', '', text)\n",
    "one_id = comments_df[comments_df['videoID'] == 'SwSbnmqk3zY'] ###not necessary in production\n",
    "comment_list = one_id['comment'].to_list()\n",
    "dirty_text = ' '.join(comment_list)\n",
    "clean = clean_text(dirty_text)\n",
    "sentiment = get_sentiment(clean)\n",
    "sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'videoID': 'pb4xXXEA8zk',\n",
       " 'views_count': 343474,\n",
       " 'likes': 9723,\n",
       " 'comments_': 365,\n",
       " 'length_': 'PT13M22S',\n",
       " 'like_ratios': 0.028307819514723095,\n",
       " 'comment_ratio': 0.0010626714103542045,\n",
       " 'polarity': 0.30313164108618657,\n",
       " 'subjectivity': 0.5348300373868556}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis['polarity'] = sentiment[0]\n",
    "analysis['subjectivity'] = sentiment[1]\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
